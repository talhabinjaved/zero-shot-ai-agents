# AI Agent Experiment Orchestrator

> Automate computational experiments end-to-end using AI agents (Jules & OpenHands)

Transform experiment ideas into complete, production-ready research repositories with automated planning, execution, and comprehensive results â€” all powered by AI.

---

## ğŸ¯ What It Does

This orchestrator takes **experiment ideas** (from CSV) and uses AI agents to:

1. **Plan experiments** - Design comprehensive experiment plans from scratch
2. **Write code** - Implement all necessary scripts (setup, baseline, experiments, analysis)
3. **Run experiments** - Execute via GitHub Actions with automated validation
4. **Generate results** - Create publication-quality RESULTS.md with visualizations
5. **Document everything** - Professional README with methods, findings, and next steps

**All without human intervention.**

---

## â­ Supported Providers

### ğŸ¥‡ Jules (Recommended)
- **Status:** â­â­â­â­â­ Production-ready
- **API:** Full REST API automation
- **Best for:** Easiest setup, most reliable
- **Features:** Auto-planning, CI iteration, PR creation
- **URL:** https://jules.google

### ğŸ¥ˆ OpenHands (Excellent Alternative)
- **Status:** â­â­â­â­â­ Production-ready
- **API:** Conversation-based API
- **Best for:** BYO models (use your own LLM API keys)
- **Features:** Auto-planning, comprehensive workflows, flexible
- **URL:** https://app.all-hands.dev

**Note:** Augment and Cosine were tested and removed:
- **Augment:** Backend failures (100% error rate)
- **Cosine:** Architectural mismatch (CI fixer, not experiment creator)

---

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Clone the repository
git clone <repository-url>
cd zero-shot-ai-agents

# Set environment variables
export GITHUB_TOKEN=ghp_your_token_here
export GITHUB_OWNER=your_github_username
export JULES_API_KEY=your_jules_key_here  # For Jules
export OPENHANDS_API_KEY=your_key_here     # For OpenHands
```

### 2. Prepare Experiment Ideas

Create `data/ideas.csv`:
```csv
title,has_experiments,idea,experiments
Analyze Stock Trends,False,Use ML to predict stock movements from historical data,
Build Recommender,False,Create a movie recommendation system using collaborative filtering,
```

### 3. Run the Orchestrator

```bash
# Interactive mode (recommended)
./run_experiments.sh

# Or run directly
cd providers/jules
python orchestrator.py --input ../../data/ideas.csv --max-concurrent 1
```

### 4. Monitor & Review

- **Jules:** Visit https://jules.google to watch progress
- **OpenHands:** Visit https://app.all-hands.dev
- **GitHub:** Check your repos for new PRs with results

---

## ğŸ“ Repository Structure

```
â”œâ”€â”€ data/                      # Experiment ideas (CSV files)
â”‚   â””â”€â”€ ideas.csv             # Your experiment ideas
â”œâ”€â”€ providers/
â”‚   â”œâ”€â”€ jules/                # Jules orchestrator (â­ Recommended)
â”‚   â”‚   â”œâ”€â”€ orchestrator.py   # Main orchestrator script
â”‚   â”‚   â”œâ”€â”€ requirements.txt  # Dependencies
â”‚   â”‚   â””â”€â”€ templates/        # Repo templates
â”‚   â””â”€â”€ openhands/            # OpenHands orchestrator
â”‚       â”œâ”€â”€ orchestrator.py   # Main orchestrator script
â”‚       â”œâ”€â”€ requirements.txt  # Dependencies
â”‚       â””â”€â”€ templates/        # Repo templates
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ QUICKSTART.md         # Detailed setup guide
â”‚   â”œâ”€â”€ CSV_FORMAT.md         # Input format specs
â”‚   â””â”€â”€ ...
â”œâ”€â”€ tests/                    # Test suite
â”œâ”€â”€ run_experiments.sh        # Interactive launcher
â”œâ”€â”€ FIXES_APPLIED.md          # Technical fixes documentation
â””â”€â”€ README.md                 # This file
```

---

## ğŸ¨ Features

### âœ… Core Capabilities
- **Dual Pipeline:** AI planning OR pre-defined experiments
- **Automated Code Generation:** Scripts, tests, documentation
- **GitHub Integration:** Auto-create repos, manage branches
- **CI/CD Automation:** GitHub Actions workflows
- **Publication-Quality Results:** Visualizations, deep analysis, statistical tests
- **Error Handling:** Retry logic, comprehensive logging
- **Reproducibility:** Seeds, versions, hyperparameters documented

### ğŸ“Š Enhanced Results Quality (Fix #12)
Both Jules and OpenHands now generate:
- **Visualizations:** Model comparisons, learning curves, error distributions
- **Deep Analysis:** Error analysis, feature importance, edge cases
- **Statistical Validation:** P-values, confidence intervals
- **Implementation Details:** Code links, hyperparameters, seeds
- **Specific Next Steps:** Actionable recommendations with expected improvements

### ğŸ›¡ï¸ Reliability Features
- **Smart .gitignore:** Results committed, models excluded
- **Timeout Handling:** 5-hour limits for complex experiments
- **Branch Detection:** Works with both `main` and `master`
- **File Update Logic:** Handles existing files correctly
- **Connection Resilience:** Auto-retry on network errors

---

## ğŸ“– How It Works

### Workflow Overview

```
1. Read Ideas (CSV)
         â†“
2. Create GitHub Repo
         â†“
3. Seed with Templates
         â†“
4. Start AI Agent
         â†“
5. AI Plans Experiments
         â†“
6. AI Implements Code
         â†“
7. AI Runs via GitHub Actions
         â†“
8. AI Validates Results
         â†“
9. AI Generates RESULTS.md (with plots!)
         â†“
10. AI Creates PR
         â†“
11. Review & Merge
```

### Example Input (CSV)
```csv
title,has_experiments,idea,experiments
Test Neural Networks,False,Compare CNN vs RNN vs Transformer on MNIST,
```

### Example Output (GitHub Repo)
```
your-username/test-neural-networks/
â”œâ”€â”€ README.md              # Professional documentation
â”œâ”€â”€ RESULTS.md             # Comprehensive findings with visualizations
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ experiments.yaml   # Complete experiment plan
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.py          # Environment setup
â”‚   â”œâ”€â”€ data_prep.py      # Data preprocessing
â”‚   â”œâ”€â”€ baseline.py       # Baseline experiments
â”‚   â”œâ”€â”€ experiment.py     # Main experiments
â”‚   â””â”€â”€ analysis.py       # Results analysis
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ plots/
â”‚   â”‚   â”œâ”€â”€ model_comparison.png
â”‚   â”‚   â”œâ”€â”€ learning_curves.png
â”‚   â”‚   â””â”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ metrics.json      # All metrics
â”‚   â””â”€â”€ results/          # Detailed results
â””â”€â”€ .github/workflows/
    â””â”€â”€ run-experiments.yml  # CI automation
```

---

## ğŸ”§ Requirements

### System Requirements
- **Python:** 3.8 or higher
- **Git:** For repository management
- **Network:** Internet connection for API calls

### API Keys Required

**For Jules:**
```bash
export GITHUB_TOKEN=ghp_your_github_token
export GITHUB_OWNER=your_github_username
export JULES_API_KEY=your_jules_api_key
```

**For OpenHands:**
```bash
export GITHUB_TOKEN=ghp_your_github_token
export GITHUB_OWNER=your_github_username
export OPENHANDS_API_KEY=your_openhands_key
```

### Get API Keys
- **GitHub Token:** https://github.com/settings/tokens (requires `repo` scope)
- **Jules API Key:** https://jules.google â†’ Settings â†’ API Keys
- **OpenHands Key:** https://app.all-hands.dev â†’ Settings

---

## ğŸ’° Cost Estimates

### Jules
- **Free Tier:** 15 experiments/day - $0/month
- **Pro Tier:** 100 experiments/day - ~$30-50/month
- **Ultra Tier:** 300 experiments/day - ~$100-200/month

### OpenHands
- **Cloud:** ~$10-100/month (usage-based)
- **Self-hosted:** Your own LLM API costs

### GitHub Actions
- **Free:** 2,000 minutes/month
- **Additional:** $0.008/minute
- **Typical:** $0-20/month for moderate usage

**Total:** $0-300/month depending on usage

---

## ğŸ“š Documentation

- **[QUICKSTART.md](docs/QUICKSTART.md)** - Detailed setup guide
- **[CSV_FORMAT.md](docs/CSV_FORMAT.md)** - Input file format
- **[FIXES_APPLIED.md](FIXES_APPLIED.md)** - All 12 technical fixes applied
- **[TEST.md](docs/TEST.md)** - Testing guide

---

## ğŸ§ª Testing

```bash
# Test CSV parsing
python -m pytest tests/integration/test_csv_parsing.py

# Test GitHub API
python -m pytest tests/integration/test_github.py

# Test provider APIs
python -m pytest tests/providers/test_jules_api.py
python -m pytest tests/providers/test_openhands_api.py
```

---

## ğŸ¯ Example Use Cases

### Research
- **A/B Testing:** Compare different ML architectures
- **Hyperparameter Tuning:** Find optimal configurations
- **Algorithm Comparison:** Benchmark approaches
- **Reproducibility:** Automated reproducible experiments

### Development
- **Proof of Concepts:** Quickly validate ideas
- **Baseline Implementations:** Generate starting points
- **Code Generation:** Automate boilerplate
- **Documentation:** Auto-generate comprehensive docs

### Education
- **Learning Projects:** Build complete ML projects
- **Course Assignments:** Automated project scaffolding
- **Tutorials:** Generate working examples

---

## ğŸ† Success Metrics

**Test Results (Current):**
- âœ… **Jules:** 100% success rate (multiple test runs)
- âœ… **OpenHands:** 100% success rate (tested successfully)
- âœ… **Artifacts committed:** Yes (Fix #11)
- âœ… **Visualizations generated:** Yes (Fix #12)
- â­ **Results quality:** 5/5 stars (publication-ready)

**Fixes Applied:** 12 major improvements
- GitHub file handling, branch detection, workflow syntax
- Repository indexing, error logging, timeout handling
- Artifacts preservation, results quality enhancement
- Connection resilience, prompt improvements

---

## ğŸ¤ Contributing

We welcome contributions! Here's how:

1. **Test thoroughly** - Run the test suite
2. **Document changes** - Update docs for any new features
3. **Follow style** - Match existing code patterns
4. **Test both providers** - Ensure Jules and OpenHands work

---

## ğŸ› Troubleshooting

### Common Issues

**"Repository not indexed"** (Jules)
- Wait 20 seconds after repo creation
- Jules auto-retries up to 6 times

**"Connection aborted"**
- Auto-retry logic handles this (Fix #10)
- Transient network errors automatically recovered

**"Artifacts not showing up"**
- Fixed in v2.0 (Fix #11)
- New repos automatically commit artifacts

**"Results lack visualizations"**
- Fixed in v2.0 (Fix #12)
- Both providers now generate comprehensive visualizations

---

## ğŸ“Š Changelog

### v2.0 (Current) - Jules & OpenHands Only
- âœ… 12 major fixes applied
- âœ… Enhanced results quality (visualizations, deep analysis)
- âœ… Artifacts preservation
- âœ… Connection resilience
- âŒ Removed Augment (backend failures)
- âŒ Removed Cosine (architectural mismatch)

### v1.0 (Original)
- Initial 4-provider support
- Basic experiment orchestration

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸŒŸ Acknowledgments

- **Jules** by Google Labs - Excellent AI coding agent
- **OpenHands** by All-Hands - Flexible conversation-based agent
- **GitHub** - Platform for automation and hosting

---

## ğŸ“ Support

- **Issues:** Open a GitHub issue
- **Documentation:** Check `docs/` directory
- **Technical Details:** See `FIXES_APPLIED.md`

---

**Ready to automate your experiments? Run `./run_experiments.sh` to get started!** ğŸš€
